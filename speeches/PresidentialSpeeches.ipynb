{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyaclement/DH/blob/master/introDH/PresidentialSpeeches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook -> created by Kameron Dunn, August 2024. Dataset ->  Miller Center of Public Affairs, University of Virginia. \"Presidential Speeches: Downloadable Data.\" Accessed March 17, 2022. data.millercenter.org."
      ],
      "metadata": {
        "id": "eokgzL8ytqlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install nltk matplotlib wordcloud\n",
        "\n",
        "# Import required libraries\n",
        "import json\n",
        "import re\n",
        "from collections import Counter, defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Uy3mxrkrlzzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "with open(\"/content/sample_data/speeches.json\", \"r\") as file:\n",
        "    speeches = json.load(file)\n"
      ],
      "metadata": {
        "id": "ZumRXZgJmEXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Lowercase the text\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
        "    return text"
      ],
      "metadata": {
        "id": "Iu_EaF6zBViX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization and stopwords removal\n",
        "def tokenize_and_filter(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "bfKabgL2BgKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all speeches into a single text\n",
        "all_text = \" \".join(speech['transcript'] for speech in speeches if 'transcript' in speech)\n"
      ],
      "metadata": {
        "id": "CPk12hjdBoYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the combined text\n",
        "cleaned_text = preprocess_text(all_text)\n",
        "\n",
        "# Tokenize and remove stopwords\n",
        "tokens = tokenize_and_filter(cleaned_text)"
      ],
      "metadata": {
        "id": "L_wyvlE1Bxr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count overall word frequencies\n",
        "word_freq = Counter(tokens)\n",
        "print(word_freq)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I6upSSd8B6W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a word cloud for all speeches\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)"
      ],
      "metadata": {
        "id": "GpzXEwFLCCVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the word cloud\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.title(\"Overall Word Cloud for All Speeches\")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OcHGjp2kCiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Organize speeches by 25-year periods\n",
        "speeches_by_period = defaultdict(list)\n",
        "for speech in speeches:\n",
        "    if 'transcript' in speech and 'date' in speech:\n",
        "        year = int(speech['date'][:4])  # Extract the year from the date\n",
        "        period_start = (year // 25) * 25  # Calculate the start of the 25-year period\n",
        "        period_label = f\"{period_start}-{period_start + 24}\"\n",
        "        speeches_by_period[period_label].append(speech['transcript'])\n"
      ],
      "metadata": {
        "id": "9vG8kY2nCldf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each 25-year period's speeches and visualize the top 20 words chronologically\n",
        "for period in sorted(speeches_by_period.keys()):\n",
        "    texts = speeches_by_period[period]\n",
        "    all_text = \" \".join(texts)\n",
        "    cleaned_text = preprocess_text(all_text)\n",
        "    tokens = tokenize_and_filter(cleaned_text)\n",
        "    word_freq = Counter(tokens)\n",
        "    most_common_words = word_freq.most_common(20)\n",
        "\n",
        "    # Visualize the top 20 words for each 25-year period\n",
        "    labels, values = zip(*most_common_words)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(labels, values)\n",
        "    plt.title(f\"Top 20 Words in {period}\")\n",
        "    plt.xlabel('Words')\n",
        "    plt.ylabel('Frequencies')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "80H4G51YCuk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define gendered words\n",
        "gendered_words = {\n",
        "    'he': 0, 'him': 0, 'his': 0, 'man': 0, 'men': 0,\n",
        "    'she': 0, 'her': 0, 'hers': 0, 'woman': 0, 'women': 0\n",
        "}\n",
        "\n",
        "# Count gendered words in each 25-year period\n",
        "gendered_words_by_period = defaultdict(lambda: defaultdict(int))\n",
        "for period, texts in speeches_by_period.items():\n",
        "    all_text = \" \".join(texts)\n",
        "    cleaned_text = preprocess_text(all_text)\n",
        "    tokens = tokenize_and_filter(cleaned_text)\n",
        "\n",
        "    # Count the occurrences of gendered words\n",
        "    for word in tokens:\n",
        "        if word in gendered_words:\n",
        "            gendered_words_by_period[period][word] += 1\n",
        "\n",
        "# Visualize gendered words by period\n",
        "for period in sorted(gendered_words_by_period.keys()):\n",
        "    labels, values = zip(*sorted(gendered_words_by_period[period].items()))\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(labels, values, color=['blue' if word in ['he', 'him', 'his', 'man', 'men'] else 'pink' for word in labels])\n",
        "    plt.title(f\"Gendered Words in {period}\")\n",
        "    plt.xlabel('Words')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "v6Kw0uN4DNHp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
